# ASRT_SpeechRecognition
基于深度学习的语音识别系统

## Introduction

这里是更新记录日志文件

如果有什么问题，可以在这里直接写出来

## Log
### 2018-07-06
添加一个新的模型，编号251，一个基于模型25改进的模型。
### 2018-06-30
m25模型已经可以使用了，并且在release中进行了发布。正确率基本达到80%，可以初步进行使用了。另外，目前的模型总感觉哪里有识别性能的瓶颈，正确率似乎在这里就到了极限了？
### 2018-05-21
已经在release里面预发布了一个用了模型22的软件，准确率在70%左右。模型23使用了人工特征提取算法MFCC，模型更小参数更少，可以在相同情况下获得跟模型22一样的正确率，而一个层数更深的模型24也可以训练使用了。
### 2018-05-02
已经将st-cmds的免费公开数据集加入了数据集列表中，现在是两个数据集一起在使用。st-cmds下的标注拼音列表是本人自己用自制的自动数据标注工具生成的，不属于原来的数据集的内容，所以部分标注也许有错误，这是在所难免的，欢迎各位来提交数据中的标注错误内容。
### 2018-04-25
将语音模型和语言模型打通，模型22目前效果最好，测试集上准确率在70%左右。数据集上，仅仅使用THCHS30可能不够。
### 2018-04-13
从理论上分析了一下，觉得的确只有模型2这种二维的方法才会有用，模型1和模型3,4,5应该都是错误的。

另外就是，处理了一下输入的频率特征，针对复数频率特征做了特别处理，即分别取出实部和虚部。
### 2018-04-10
目前好像只有模型2能够一定程度上识别出来内容。。不过正确率仍然很差。。目前发现训练起来速度特别慢，而且读取数据的时间很长且是单线程操作，准备将数据做预处理，训练时直接加载读取处理后的数据，以提高训练速度和并行度。
### 2018-04-08
经过连续几天的不懈努力，loss终于可以下降了。原因竟然是模型的权重参数初始化有问题，直接导致了梯度的消失，以至于难以训练，loss迟迟下不来，一直欠拟合。调参的第一坑...
### 2018-04-05
将之前的模型做了修改，并且，想用图像的方式试试效果。现在对于loss下不来acc上不去这个问题很头大。
### 2018-03-30
暂时能够正常训练模型了，修复了一大堆bug问题，也在这个过程中学到很多。感谢队友和所有直接或间接帮助过我的各位大大。继续前进！
### 2018-03-28
CTC这一块似乎添加成功了？现在开始debug了。。。
现在也许可以开始训练了
### 2018-03-11
添加了神经网络的CTC层和定义了CTC_loss损失函数，但是现在有些严重的bug，使得模型无法正常编译，一直找不到问题所在......(T_T)
#### 报错 
ValueError: Shapes (?, ?) and (?,) must have the same rank

ValueError: Shapes (?, ?) and (?,) are not compatible

ValueError: Shape (?, ?) must have rank 1
#### --------------------------------
各位走过路过的大神有会的吗？请帮帮忙吧，ヾ(o′▽`o)ノ°°谢谢啦
### 2017-09-08
基本完成除了添加模型之外的其他部分代码
### 2017-08-31
数据处理部分的代码基本完成，现在准备撸模型
### 2017-08-29
准备使用现有的包[python_speech_features](https://github.com/jameslyons/python_speech_features)来实现特征的提取，以及求一阶二阶差分。
### 2017-08-28
开始准备制作语音信号处理方面的功能
### 2017-08-22
准备使用Keras基于LSTM/CNN尝试实现

